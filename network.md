# OSI (open system interconnection reference model) 七层协议
1. 物理层
发送电信号 0101
2. 数据链路层
将电信号分组, 一组电信号称为一帧, 通过 mac 地址找到同一局域网内的机器
3. 网络层
为了找到不同局域网的机器, 提供了 ip 地址, 并提供 ==ARP (Address Resolution Protocol)== 将 ip 地址解析为 mac 地址. 如果要找到跨局域网的机器, 则本计算机通过子网掩码判断出对方 ip 不在同个局域网, 因此将数据先发送给网关
4. 传输层
找到了对方的机器, 此时为进程提供通信服务, 因为有多个端口. 该层有 TCP 和 UDP 两种协议
5. 应用层
http, dns

## 交换机路由器区别
工作层次不同：
交换机主要工作在数据链路层（第二层）
路由器工作在网络层（第三层）。
转发依据不同：
交换机转发所依据的对象时：MAC地址。（物理地址）
路由转发所依据的对象是：IP地址。（网络地址）


# 网络层
## 路由算法


# 传输层
## TCP (transmission control protocol)
> TCP把连接作为最基本的对象，每一条TCP连接都有两个端点，这种端点我们叫作套接字（socket），它的定义为端口号拼接到IP地址即构成了套接字，例如，若IP地址为192.3.4.16 而端口号为80，那么得到的套接字为192.3.4.16:80。

### TCP 报文
![](https://camo.githubusercontent.com/690200ac72bf19ad2e859901f61d7e4d3a21c83608d9dd62a1146eca359cf655/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35356463346538342d353733642d346331332d613736352d3532656431646432353166392e706e67)

- 源端口和目的端口，各占2个字节，分别写入源端口和目的端口；
- 序号，占4个字节，TCP连接中传送的字节流中的每个字节都按顺序编号。例如，==一段报文的序号字段值是 301 ，而携带的数据共有100字段，显然下一个报文段（如果还有的话）的数据序号应该从401开始；==
- 确认号，占4个字节，是期望收到对方下一个报文的第一个数据字节的序号。例如，==B收到了A发送过来的报文，其序列号字段是501，而数据长度是200字节，这表明B正确的收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701；==
- 数据偏移，占4位，它指出TCP报文的数据距离TCP报文段的起始处有多远；
保留，占6位，保留今后使用，但目前应都位0；
- 紧急URG，当URG=1，表明紧急指针字段有效。告诉系统此报文段中有紧急数据；
- 确认ACK，仅当ACK=1时，确认号字段才有效。TCP规定，在连接建立后所有报文的传输都必须把ACK置1；
- 推送PSH，当两个应用进程进行交互式通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应，这时候就将PSH=1；
- 复位RST，当RST=1，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立连接；
- 同步SYN，在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1；
- 终止FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放；
- 窗口，占2字节，指的是通知接收方，发送本报文你需要有多大的空间来接受；
- 检验和，占2字节，校验首部和数据这两部分；
- 紧急指针，占2字节，指出本报文段中的紧急数据的字节数；
- 选项，长度可变，定义一些其他的可选的参数。

### TCP连接的建立（三次握手）
![](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA1MTEwNDA1NjY2?x-oss-process=image/format,png)

1. 客户端发送连接请求报文, 其中报文首部中的 SYN 标志设置为1, 序号seq设为 x(随机生成, 防止伪造), 进入 SYN_SENT 状态 (TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。)
2. 服务端收到这个请求报文, 同意建立请求, 返回确认报文, 其中首部 ACK 标志设置为 1, 确认序号 ack = x + 1, 同时, 这个报文也是一个请求连接报文, 因此 SYN = 1, 序号 seq = y, 进入 SYN_RCVD(recieved) 状态 (这个报文也不能携带数据，但是同样要消耗一个序号。)
3. 客户端收到该报文, 返回一个确认报文, ACK = 1, ack = y+1, seq = x + 1 (TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号)

#### 为什么要进行最后一次握手
1. 防止建立重复连接
如果是两次连接, 那么第一次握手如果超时重发(==客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了==), 那么服务端将会首先建立起一次连接, 等到客户端的第一个请求报文到达后, 又建立一次连接
但是三次握手, 服务端没有收到第二次连接的第三次握手, 则不会开启连接
2. 从双方确立可靠通信的角度
第一次握手, 客户端什么都不能确定, 服务端确定自己的接收, 对方的发送功能正常
第二次握手, 客户端确定自己的发送接收, 对方的发送接收正常, 而服务端确定自己的接收, 对方的发送正常
第三次握手, 双方确定彼此的发送接收正常

#### SYN 泛洪攻击

攻击者伪造大量的 Ip, 向服务器发送 tcp 请求, 而服务器接收到第一次握手后, 将处于 SYN_RCVD 状态, 并将其放在半连接队列里, 而发送二次握手没有回应, 重传多次后再将其丢弃. 

> 目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s, 总共31s, 称为指数退避，第5次发出后还要等32s才知道第5次也超时, 所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s, TCP才会把断开这个连接
对于应对SYN 过多的问题，linux提供了几个TCP参数
![](https://pic1.zhimg.com/80/v2-f998ee97330a3a258ad617ea10257c4c_1440w.jpg)

1. 检测, 使用 netstat 指令可以看到大量连接处于 SYN_RCVD 状态
2. 解决
    - 缩短超时时间
    - 增加半连接队列长度
    - SYN_cookie
    ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xODQ1MjUzNi04YzRkZjBjYWZiMmRiMjE3?x-oss-process=image/format,png)
    1. 与前面接收到SYN 报文就分配缓存不同，此时暂不分配资源；同时利用SYN 报文的源和目的地IP和端口，以及服务器存储的一个秘密数，使用它们进行散列，得到server_isn，然后附着在SYNACK 报文中发送给客户端，接下来就是对ACK 报文进行判断，如果其返回的ack字段正好等于server_isn + 1，说明这是一个合法的ACK，那么服务器才会为其生成一个具有套接字的全开的连接。
    2. 当然这种方案也有一定缺点，最明显的就是服务器不保存连接的半开状态，就丧失了重发SYN-ACK消息的能力，这一方面会降低正常用户的连接成功率，另一方面会导致某些情况下正常通信的双方会对连接是否成功打开产生误解，如客户端发给服务端的第三次握手消息（ACK）半路遗失，客户端认为连接成功了，服务端认为没收到ACK，连接没成功，这种情况就需要上层应用采取策略特别处理了

### TCP连接的释放 (四次挥手)

![](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png)

1. 客户端发送连接释放报文, 其中首部的 FIN 标志设置为 1 , 序号 seq = u (前面传送过去的最后一个字节序号加1), 此时进入 FIN-WAIT-1(终止等待2状态) 状态. 此时客户端不能再传送数据 ==TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。==
2. 服务端收到连接释放报文, 返回确认报文, ACK=1, 确认序号 ack = u+1, 带上自己的序号 seq = v, 此时服务端仍能发送数据, 持续 CLOSE-WAIT(半关闭状态) 时间
3. 客户端接收到服务器的确认后, 进入 FIN-WAIT-2 (终止等待2状态) 
4. 服务端没有数据发送了, 发送连接释放报文, 报文 FIN=1, ack = u+1, 序号 seq = w (传送的最后数据序号+1), 服务端进入 LAST-ACK 状态.
5. 客户端接收到服务端的连接释放报文, 发送确认报文, 其中 ACK=1, ack=w+1, seq=u+1, 此时客户端进入 TIME-WAIT(时间等待) 阶段, 此时客户端 TCP 还没有释放, 需要等待 2*MSL(maximum section lifetime, 最长报文寿命), 才进入 CLOSE 状态
6. 服务端一接收到客户端的确认报文, 立即进入 CLOSE 状态

#### MSL 怎么得到
MSL是任何IP数据报能够在网络中存活的最长时间。我们知道这个时间是有限的，因为每个数据报含有一个称为跳限（hop limit）的8位字段，它的最大值是255，即最大为255跳。尽管这是一个跳数限制而不是真正的时间限制，我们仍然假设：具有最大跳限的数据报在网络中存在的时间不可能超过MSL秒。
任何TCP实现都必须为MSL选择一个值。RFC 1122的建议值为2分钟，对于现在的网络，MSL = 2分钟可能太长了，故一些实现采用30秒的值，这意味着，TIME-WAIT状态的持续时间在1分钟到4分钟之间

### TCP如何实现可靠传输
1. 超时重传
2. arq (Automatic Repeat reQuest)协议
3. 数据分包, 编号
4. 校验和
存在于 tcp 报文首部, 保存着首部和数据的检验和
5. 拥塞控制
6. 流量控制

#### ARQ 协议
自动重传请求（Automatic Repeat-reQuest，ARQ）是==OSI模型中数据链路层和传输层==的错误纠正协议之一
##### 停止等待 ARQ
每发完一个分组即停止等待回复
##### 连续ARQ
维护一个发送窗口, 处于发送窗口中的分组可以连续发送, 而接收方只需要对最后一个有序分组确认
缺点: 可能需要回退多个, 如中间某一个丢失, 将从该包到最后一个包再发送一次
##### 确认丢失
A 向 B 发送 M1 消息, B 收到后发送的确认消息丢失, 此时 A 再次发送 M1 消息, 则 B 收到后, 1) 丢弃该消息 2) 再次向 A 发送确认消息
##### 确认迟到
A 向 B 发送 M1 消息, B 收到后发送的确认消息丢失, 此时 A 再次发送 M1 消息, 则 B 收到后, 再次发送确认消息, A, B 继续传送消息, 一段时间后, A 收到 B 第一次发送的 M1 确认消息, 直接丢弃

#### 流量控制
tcp 接收双方都维护一个滑动窗口, 接收方通过 tcp 首部的窗口字段来告诉发送方自己的窗口大小, 发送方根据该值和其他信息来设置自己的窗口大小
比如, 接收方可以将该值设置为 0, 则发送方不能发送数据
#### 拥塞控制
如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。
==tcp 主要通过四个算法实现拥塞控制: 慢开始, 拥塞避免, 快恢复, 快重传==
发送方需要维护一个**拥塞窗口 (cwnd)** 的状态变量, 与发送窗口的区别: cwnd 只是一个状态变量, 实际能发送多少数据还是由发送窗口控制, 事实上, 发送窗口约等于 cwnd 和接收窗口的较小值

![](https://camo.githubusercontent.com/96b543c35dfc6a024897cea0354427605b9d238d7af0e8c5821c7ab0c26c2f27/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f39313066363133662d353134662d343533342d383764642d3962343639396435396433312e706e67)

1. **慢开始和拥塞避免**
最开始执行慢开始, 即 cwnd = 1, 此后每次收到确认报文将 cwnd 翻倍, 2, 4, ...
当达到设定的 ssthrech, 进入拥塞避免, 即每轮将 cwnd + 1
而如果遇到超时重发, 则将 ssthrech = cwnd/2, cwnd = 1
2. **快重传和快恢复**
如果某次连续收到三个同样的确认报文, 则可确认下一个报文丢失, 此时立即执行快重传, 传输下一个报文.
同时, 由于只是丢失个别报文, 并非网络拥塞, 所以执行快恢复, 将 ssthrech = cwnd/2, cwnd = ssthrech, 即马上进入拥塞避免

### TCP "粘包问题"
1. 其实 TCP 协议是面向字节流的, 本身不存在包的概念, 并且 TCP 已经明确可能将用户数据拆分
2. 所谓粘包问题
    ![](https://user-gold-cdn.xitu.io/2020/3/7/170b2877abc959d3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
    1. 发送端应用层写入数据小于套接字缓冲区大小
    ![](https://user-gold-cdn.xitu.io/2020/3/7/170b28766f2164b5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
    2. 发送端应用层写入数据大于套接字缓冲区大小, 导致拆包
    3. 接收端不及时读取套接字缓冲区, 导致粘包
3. 解决方法(应该在应用层解决)
    1. 约定以特殊的字符作为分割, 如`\r\n`
    2. 接收固定长度的消息作为一个包
    3. 分为包头和包体, 包头指示该包长度(http采用)
## UDP (User Datagram Protocol)
![](https://pic1.zhimg.com/v2-fa0fa846a1c792845356f590a25f5574_b.png)
### 伪首部
根据IP报文首部获得8字节的源地址+目的地址、2字节的0字段+UDP协议字段、2字节的数据长度，得到12字节伪首部
发送方将UDP伪首部、首部、数据每16位一组进行二进制反码求和，再将求和结果求反码，填入校验和字段后伪首部消失
接收方收到UDP报文后，生成伪首部，将伪首部、首部、数据每16位一组进行二进制反码求和，若求和结果全为1则无差错传输，否则丢弃
### 与 tcp 的区别
1. udp 面向报文, 无连接, 对于应用层的下发的报文既不拆分, 也不合并, 而 tcp 面向连接
2. udp 不保证报文到达顺序
3. udp 不提供可靠传输 (超时重传, 流量控制, 拥塞控制)
4. udp 结构简单, 包的头部只有8个字节, 相比于 tcp 的 20 个字节开销较小


# 应用层
## 什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？
每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。

（PS：RIP是应用层协议：https://www.zhihu.com/question/19645407 ）

优缺点
实现简单，开销小
随着网络规模扩大开销也会增大；
最大距离为15，限制了网络的规模；
当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器

## 常见应用端口及协议
| 应用程序 | FTP | TFTP | TELNET | SMTP	| DNS | HTTP | HTTPS | SSH | MYSQL |
| - | - | - | - | - | - | - | - | - | - |
| 熟知端口 | 21,20 | 69 | 23 | 25 | 53	| 80 | 443 | 22 | 3306
| 传输层协议	| TCP | UDP | TCP | TCP | UDP |TCP | TCP | TCP | TCP
## HTTP
![](https://img2018.cnblogs.com/blog/885859/201907/885859-20190724173242717-440362909.png)

### HTTP方法
1. GET
2. HEAD: 与GET类似, 但是没有响应体, 主要用于确认 URL 的有效性以及资源更新的日期时间等。
3. POST
4. PUT
5. DELETE

#### GET 与 POST 区别
其实并无实质区别, 只是==报文格式不同==
1. 报文头部方法名不同
2. 参数位置不同, GET 在 url, POST 在 body
3. 安全性而言, 二者其实都不安全, 因为 http 是明文传输, 安全应该考虑 https
4. GET 方法长度限制. http 并无对 header 和 body 有长度限制, 但是浏览器和服务器可能会有限制
5. POST 方法并非一定产生两个 tcp 数据包
6. GET 方法可以被浏览器缓存(也可以做书签), POST 方法不可以, 因为非幂等(每次执行效果相同)

### HTTP 响应码
- 100: continue. 继续, 客户端应该继续其请求
- 200: OK
- 206: Partial Content. 部分内容, HTTP1.1 加入
- 301: moved permanently. 永久重定向
- 302: found. 临时重定向
- 304: not modified. 内容未修改
- 400: bad request. 客户端语法错误, 服务端不能理解
- 401: unauthorized. 未授权
- 403: forbidden. 请求被拒绝
- 404: not found
- 409: conflict. 请求资源与资源当前状态冲突. 例如，在上传比服务器上已存在的文件更早的文件时，您可能会收到409响应，从而导致版本控制冲突
- 410: gone. 服务器某个资源已永久删除
- 416: Requested Range Not Satisfiable. 范围请求越界
- 500: internal server error. 服务端内部错误
- 502: bad gateway. 网关或代理执行请求时, 收到服务端无效响应
- 503: server unavailable. 服务端正在维护

### HTTP优化方向
影响一个 HTTP 请求的因素主要有两个: **带宽**和**延迟**
1. 带宽: 现在的通讯技术带宽已经提升很快, 并且带宽也不是 HTTP 能改变的
2. **延迟**:
    1. 线头阻塞 (head-of-line blocking)
    2. dns 查询: 可以利用 dns 缓存解决
    3. 建立连接过程(三次握手, 四次挥手)

#### HTTP 1.0 和 HTTP 1.1
1. **缓存**
在 HTTP1.0 主要使用头部的 if-modified-since, expire 作为缓存判断标准, 而 HTTP 加入 if-unmodified-since, if-match, if-unmatch
2. **带宽优化**
HTTP1.1 在头部加入 range 头域, 允许只请求资源的某个部分, 同时引入状态码 206(部分内容), 416(范围越界), 因此也支持断点续传
3. **响应码**
新增响应码, 如 206, 416, 409, 410
4. **长连接**
HTTP1.1 默认开启长连接(头部 connection : keep-alive), 即一个 tcp 连接可以传输多个 http 请求
5. **host头处理**
请求中强制要求加入 host, 否则报告 400 响应. 原因在于一个物理服务器可以有多台虚拟主机

#### HTTP 2.0
- **二进制格式传输**
HTTP1 是基于文本, 由于文本的表现方式多样, 因此要做到健壮必须考虑多场景
- **多路复用**
- **头部压缩**
![](https://st.imququ.com/i/webp/static/uploads/2015/10/hpack-header-compression.png.webp)
    1. 浏览器和服务端维护一份相同的静态字典, 可用于 
        1) 根据静态字典直接使用一个字符表示, 如上图中的2可以直接表示 :method GET 
        2) 根据静态字典更新动态字典, 如上图中的 19 huffman("/resource"), 此时浏览器将 value 进行霍夫曼解码后, 将动态字典的 :path 值更新
    2. 维护一份相同的动态字典(每个连接一份)
- **服务端推送**
能免去客户端发起请求, 如静态资源
![](http://mmbiz.qpic.cn/mmbiz_png/cmOLumrNib1cfBOtIMQ6JfSibJdd6QkQribkZLpDyHlTbAGkEiazqLfjkTSfMgib2UlC0p3Yw0T3iaaHcvLjL22PZWPg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
![](http://mmbiz.qpic.cn/mmbiz_png/cmOLumrNib1cfBOtIMQ6JfSibJdd6QkQribq79os9yK2JmEODZqRVBweS7uMP2WWz4Ij6Z1f9TuiaXANOozhwCWljw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### HOL (head of line blocking)线头阻塞问题

![](https://upload-images.jianshu.io/upload_images/6383319-0038959f76865b38.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/550/format/webp)

1. **http1.0**
默认短连接, 导致连接无法复用, 每次请求都要经历三次握手和慢启动
2. **http1.1**
pipelining(流水线), 在一个 tcp 连接连续发送多个 http 请求, 但是仍然没有解决 hol, 因为响应遵循 FIFO, 因此如果请求 1 阻塞了, 后续请求也不会返回响应
3. **http2.0**
多路复用, 在应用层和传输层之间新增一个二进制分帧层
![](https://www.zhoulujun.cn/uploadfile/net/2019/0118/20190118175213765118834.jpg)
这样允许 http 在一次请求中发起多个请求与响应
![](https://www.zhoulujun.cn/uploadfile/net/2019/0118/20190118175213461327914.png)
一个 request 对应一个 steam id, 这样一个连接可以有多个 steam, 每个 steam frame 可以随机混杂在一起; 接收方可以根据 steam id 将frame 再归属到不同的 request
![](https://www.zhoulujun.cn/uploadfile/net/2019/0118/20190118175213757020084.png)
    ##### 为什么 HTTP1.x 时代不能使用多路复用
    因为 http1.x 是基于文本协议, 他不会区分负载的资源. 如果我们尝试将其分包
    ![](https://pic4.zhimg.com/80/v2-ab3d635cd31de6073cb5981c6a069b6f_720w.jpg)
    那么他将把 css 解析成 js 文件的一部分
==**http2.0 只解决应用层的 hol**==
因为 http2.0 依然基于 tcp 连接, 所有他不能解决 tcp 带来的 hol
![](https://pic3.zhimg.com/80/v2-1e46e710eabe4ffc824c715c17c245a6_720w.jpg)
如上图, 如果传输过程中, 2号 tcp 报文丢失, 1,3 正常到达, 由于 2 号报文丢失, 而 tcp 需要按照序号交付报文, 因此 3 号报文将被保存在缓冲区直到 2 号报文重传. 也就是说, **丢失的 2 号报文线头阻塞了 3号**

4. **http3.0** 
RUDP (reliable UDP)
建立在应用层和传输层之间, 如 Google 开发的 QUIC(Quick UDP Internet Connection). 
![](https://pic2.zhimg.com/80/v2-86bbaaa921547967e243e9d46ca22a31_720w.jpg)
与 HTTP/2 的数据帧（DATA frames）非常相似，**QUIC 的流帧（STREAM frames）分别跟踪每个流的字节范围。**
如果此时 2 号报文丢失, 1,3 号到达, 此时 QUIC 可以查看 steam1 的字节范围, 发现3号报文的steam1 与1号报文之间并无字节空隙, 因此可以直接交付; 而对于 steam2, 他发现一个缺口, 因此将其保留, 直到 2 号报文重传
不过, 也有其他后果, **QUIC 在单个资源流中保留了顺序，但不再跨单个流（individual streams）进行排序。**, 比如当 1 号报文丢失, 浏览器可能先看到 2 号报文.

#### HTTPS (HTTP over Securesocket Layer)
HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。
##### 加密
1. **对称加密**
![](https://camo.githubusercontent.com/6c294912997faa05a28d069a85582276f8885e1e5fd8cea3318239f2d2bb08ea/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37666666613462382d623336642d343731662d616430632d6138386565373633626237362e706e67)
优点: 运算快
如 AES (advanced encryption standard)

2. **非对称加密**
![](https://camo.githubusercontent.com/8ebc0cef52df1490899222ffeb3fa231bc19a2f2eb8fb32dac0611af865ea577/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33396363623239392d656539392d346464312d623862342d3266396563393439356362342e706e67)
如 RSA, 利用了大数质因数分解困难

3. **https 采用的加密**
    1. 利用非对称加密, 获得加密算法的密钥
    2. 通信使用 1 得到的密钥进行对称加密
![](https://camo.githubusercontent.com/34cc60de23ad2228d3877e97ed1605fa9b858dda8610de5e3201144e3b35983a/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f486f772d48545450532d576f726b732e706e67)

HTTPS劫持: 有可能被中间人攻击, 如 X 冒充 B, 给 A 发 X 的公钥, 这样 X 就能解密 A 发的密文

##### 证书
![](https://labuladong.github.io/algo/pictures/%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF/7.jpg)

现在正规的浏览器, 大都自带预存了正规认证机构的证书(包括其公钥)

##### https 连接过程
![](https://camo.githubusercontent.com/d8d5b0061ad8fcd9b9b35c662856e696c9ab1edc7648535b68ca733020919a69/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031392f342f32322f313661343538333963656163626235323f773d3138333426683d3130383026663d706e6726733d313537363832)

0. 服务器向证书认证机构申请数字证书, 并向其发送自己的公钥 e1
1. 机构确认身份(线上, 线下)后, 用自己的私钥 d2 签名 e1, 将 e1(还有签发时间, 域名, 上一级证书是否有效等), sign 打包成证书发送给服务器
2. 浏览器向服务器发送请求, 同时发送一个随机数 r1
3. 服务器返回证书, 同时发送随机数 r2
4. 浏览器根据内置的机构公钥 e2 解密签名 sign 得到 e1', 与证书上的 e1 进行对比
5. 一致则确认服务器, 生成第三个随机数 r3, 用公钥 e1 加密后发送给服务器, 至此, 双方都拥有三个随机数, 将其作为对称加密的密钥 d
6. 此后双方使用对称加密密钥通信

- 为什么需要三个随机数?
多个随机数种子来生成秘钥不容易被暴力破解出来
### 重定向和转发
**forward（转发)**：
是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程是在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址.
**redirect（重定向）**：
是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.

==转发是服务器行为，重定向是客户端行为。==
**区别**:
1. url: 重定向改变, 转发不变
2. 共享资源: 重定向不共享, 转发共享 request
3. 效率: 重定向低于转发, 因为是两次 request

**应用**:
重定向: 用户注销时跳转回主页
转发: 用户登录时转发到指定模块

### cookie和session区别
两者都是用于保存用户的会话信息
1. cookie 保存在浏览器, session 保存在服务端
2. cookie 不是很安全, 可能会有跨域攻击的危险

session 失效时间:
session本身有一个存活时间，在tomcat中默认的是30分钟，
### websocket
HTTP协议有一个的缺陷为：通信只能由客户端发起。在一些场景下，这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。我们只能使用轮询：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。最典型的场景就是聊天室。
轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）

相同点主要有：
- 都是基于TCP的应用层协议；
- 都使用Request/Response模型进行连接的建立；
- 在连接的建立过程中对错误的处理方式相同，在这个阶段WS可能返回和HTTP相同的返回码；
都可以在网络中传输数据。

不同之处在于：
- WS使用HTTP来建立连接，但是定义了一系列新的header域，这些域在HTTP中并不会使用；
- WS的连接不能通过中间人来转发，它必须是一个直接连接；
- WS连接建立之后，通信双方都可以在任何时刻向另一方发送数据；
- WS连接建立之后，数据的传输使用帧来传递，不再需要Request消息；
- WS的数据帧有序。
- http协议是短链接，因为请求之后，都会关闭连接，下次请求需要重新打开链接。websocket协议是一种长连接，只需要通过一次请求来初始化连接，然后所有请求和响应都是通过TCP链接进行通信