# ACID (事务的四大特性)
- atomicity(原子性): 事务, 不可分割的最小单元. 回滚可以用 undo log 实现
- consistency(一致性): 事务前后保持正确的状态, (如果出现转账后 A 的账户余额小于 0)
- isolation(隔离性): 在事务提交前, 对于其他事务是不可见的
- durability(持久性): 一旦提交, 将永远保存

![](https://camo.githubusercontent.com/d688683e3f6fb14d059412247e4f427a7cd1aa7686417bc552e061628f24dd84/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373231303433373032332e706e67)

# 并发一致性问题
## 1. 丢失修改
一个事务的更新操作被另一个事务的更新操作替换
![](https://camo.githubusercontent.com/43e0bcae7603de0e236f6e4c73ac4343c279d00a2dc8f144cadf368caabd565a/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232313734343234342e706e67)
## 2. 读脏数据
读到其他事务未提交的数据, 此时若该事务回滚, 则读到的数据不正确
![](https://camo.githubusercontent.com/153121db732e2d471cd447a0bead75acd302d68962b36ba391d607141a701654/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232313932303336382e706e67)
## 3. 不可重复读
在事务执行过程中, 两次读取的数据不一致, 这是因为, 在此期间读到其他事务提交前后的数据
![](https://camo.githubusercontent.com/718d52fc7785b8c4c6878b8218adcad1a8c66b8a05fc5a581226e7c9950db004/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232323130323031302e706e67)
## 4. 幻读
与不可重复读类似, 不过是读到的范围不一致
![](https://camo.githubusercontent.com/5f8d71358b5743f013a80fc9d20563d2ac6a21a514c0d7ff9a4b1db6388a6bd7/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232323133343330362e706e67)

# 封锁
## 封锁粒度
- 表级锁
- 行级锁

锁粒度越大, 并发越低
锁粒度越小, 频繁加锁, 释放锁的系统开销越大
应该在 系统开销 和 并发控制 之间做平衡

## 封锁类型
### 1. 读写锁
- 互斥锁 (Exclusive): 写锁, X 锁
- 共享锁 (Shared): 读锁, S 锁

锁的兼容关系
![](https://camo.githubusercontent.com/c04b0f9003db3c86021fd3d61d95f44342bf87c5e1c1ca74654080dc48b5205b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373231333532333737372e706e67)

### 2. 意向锁(都是表锁)
原因 : 在给一张表上写锁时, 需要对每一行都检查是否上锁, 非常耗时
规定 : 
1. 在事务获得表或行的 S 锁之前, 必须先获得 IS 锁 IX 锁
2. 在获得 X 锁之前, 必须先获得 IX 锁

各种锁的兼容性: 
![](https://camo.githubusercontent.com/69fa31ccb1308138411ff97e3b1021bdb84bfbbf786d722085461995027c31bb/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373231343434323638372e706e67)

解释: 
1. 意向锁都是互相兼容, 因为并未真正加锁
2. 这里的兼容表示表级别, 如果有两个事务对两个数据行分别加锁, 那么可以完成, 因为 IX/IS 彼此兼容

# 三级封锁协议
## 1. 一级封锁
对一个数据修改, 必须获得 X 锁, 可以==解决修改丢失==
![](https://camo.githubusercontent.com/bf114f3f2deb51dcc5c4add4c0533670dcc3da6e91bb33e26abb7021c8b4fdcd/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232303434303435312e706e67)

## 2. 二级封锁
对一个数据读取, 必须获得 S 锁, 读取后立即释放, 可以解决 ==脏读==
![](https://camo.githubusercontent.com/562fb5687b3a68df44c9ca50d85626d31e5f429ba8cb328f0bc26ce63126f46e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232303833313834332e706e67)

## 3. 三级封锁
对一个数据读取, 必须获得 S 锁, 到提交才释放, 可以解决 ==不可重复读==
![](https://camo.githubusercontent.com/67e5859aaf5cb0ce2aa60a44257636af20f762e205b107a519663e6811f83abc/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232313331333831392e706e67)

# 隔离级别

1. 未提交读 (Read Uncommitted)
2. 提交读 (Read committed)
3. 可重复 (Repeatable Read)
4. 可串行化 (Serializable)

![](https://camo.githubusercontent.com/1632a88a3a4fa7954026cb939edf2f8a30bb5d60a1bce4921c7e0d0e4d245739/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230373232333430303738372e706e67)

# MySQL

## 存储数据
char(n): 定长字符串, **字符(非字节)** 长度超过 n 将截取, 末尾空格不保留(因为固定长度为 n, 如果不足, 将用空格补齐), 索引速度==快(?)==, 存储上限为 255 字节.
varchar(n): 非定长字符串, **字符(非字节)** 长度超过 n 将截取, 当长度小于 n 将在实际长度最后添加 1(0-255字节时)-2(大于255字节时)表示长度, 字节末尾空格保留, 索引速度一般(因为长度过长可能只能使用前缀索引), 存储上限为 65535 字节(实际不足, 因为需要 1-2 字节存储长度)
## MVCC (多版本并发控制)
==innoDB 引擎==实现隔离级别的一种具体方式, 实现提交读和可重复读
未提交读只需读取最新状态, 无需 MVCC.
而串行化需要对所有读取的行加锁

### 基本思想
在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。==读写锁中读和写操作仍然是互斥的==，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。
脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。

### 版本号
- 系统版本号 SYS_ID : 递增, 每开启一个新事务, 系统版本号就会递增
- 事务版本号 TRX_ID : 系统开始时的系统版本号

### Undo日志
MVCC 的多版本是指多个快照, 快照存储在 Undo 日志中
```sql
INSERT INTO t(id, x) VALUES(1, "a");
UPDATE t SET x="b" WHERE id=1;
UPDATE t SET x="c" WHERE id=1;
```

因为没有使用 START TRANSACTION 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。

![](https://camo.githubusercontent.com/648b989516b41055bbd1f39ee4b61a6b0a00e0d0114632dceb1c6b91ec39dca6/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230383136343830383231372e706e67)

### ReadView
该数据结构里包含了所有未提交的事务, 并维护该列表里的最小和最大 TRX_ID
![](https://camo.githubusercontent.com/1fe81e9af90e3b9256a607920773eab0c685bda03fbb947a2c1a4d26ff55c21e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f696d6167652d32303139313230383137313434353637342e706e67)

当事务在进行 select 操作时, 会比较 TRX_ID_MIN, TRX_ID_MAX 和该数据行的 TRX_ID 的关系
1. 当 TRX_ID < TRX_ID_MIN, 表示该数据行更新于所有未提交事务之前, 可以读取
2. 当 TRX_ID > TRX_ID_MAX, 表示该数据行更新于所有未提交事务之后, 不可以读取
3. 当 TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX
    1. 提交读, 当该 TRX_ID 在 ReadView 列表中时, 不可使用. 若不在时, 说明已提交, 可用
    2. 可重复读, 都不可用

如果不满足, 需要在 Undo 日志中寻找上一个 TRX_ID, 再次重复上述操作

==已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView==
![](https://pic3.zhimg.com/80/v2-f52d8559ba58256df25735e761fd7ae2_1440w.jpg)

考虑这样的场景
1. 记录 a=1, trx=100
2. 开启事务1 trx = 101, 修改 a=2 之后未提交
此时记录a=2, trx=101, undo log 的上一条记录是 a=1, trx=100
3. 开启事务2 trx=102, 读取 a,
获得此时的 readview, 有 trx=101 和 102, 此时 a 的最新 trx = 101, 且在 readview 中, 因此说明未提交的事务, 不可见, 返回上一条 a = 1
4. 事务1 提交
5. 事务2 读取 a
**提交读**: 新建一个 readview, trx = [102], a 的最新 trx = 101, 小于 102, 可读, 得到 a=2
**可重复读**: 使用第一次的 readview, trx = [101, 102], 因此 a = 2 还是不可读, 返回 a = 1


### 快照读与当前读
1. 快照读
MVCC 的 select 操作是快照中的数据, 不需要加锁
2. 当前读
可以选择加锁
    ```sql
    select * from t in share mode;
    select for update
    ```

## Next-key locks
MVCC 不能解决幻影读, nkl 为了解决此问题诞生的
### record lock
锁定索引, 而非记录, 如, 11, 14
### gap lock
锁定两个索引之间的空隙, 如 (11, 14)
### next-key locks
上述两者的结合, 是一个前开后闭的区间, (]
如果一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：
```java
(上一个索引值, 如果没有, 则为 -∞, 10]
(10, 11]
(11, 13]
(13, 20]
(20, 下一个索引值, 如果没有, 则为 +∞)
```

## 索引
### 为什么使用索引
1. 加快检索速度
2. 索引自带排序
3. 将随机 I/O 转换为顺序 I/O 

### MySQL的两种索引
#### 哈希索引
根据 Hash 函数定位到数据所在的位置，这是 B+树所不能比的。
==Hash 索引不支持顺序和范围查询(Hash 索引不支持**顺序**和**范围查询**是它最大的缺点。==

InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。
#### B+树索引
##### MyISAM
非聚簇索引, 索引存储的 data 是指针
##### InnoDB
索引就是数据文件本身, 树的叶节点 data 存储了完整的数据记录, 索引的 key 是数据的主键(聚集索引). 
其余的索引都作为辅助索引, 辅助索引的 data 域存储的是主键的值. 因此，在设计表的时候，
1. 不建议使用过长的字段作为主键，
2. 也不建议使用非单调的字段作为主键，

这样会造成主索引频繁分裂

###### 聚簇索引的优点
1. 当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好(因为顺序IO)。
2. 当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。
3. 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

##### B+树的基本存储结构
MySQL 的基本存储结构是页(==16KB==)
![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-2/28559421.jpg)
![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-2/82053134.jpg)
![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-2/5373082.jpg)
![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-2/89338047.jpg)
##### 和 B树 的区别
1. B树的所有节点即存储索引, 又存储 data, 而B+树只在叶子节点存储 data
2. B+ 树的叶子节点存在一条指向下一个节点的引用链, 这样在遍历时能够加快速度. 而B树的叶子节点是独立的
3. 因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出), ==指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；==
##### 与红黑树相比
1. 都是自平衡树
2. 红黑树的出度为2, 意味着红黑树的树深度更大, 也就是要查找到一个节点需要更多的 I/O 操作
3. ==~~B+树的一个节点大小设置为磁盘一个页的大小, 这样一次 I/O 可以读入一整个节点~~==
> 磁盘的最小的存储单元是块 (4k), mysql 的 innoDB 一个页大小为 16K, 因此应该是利用到预读, 在一次 I/O 时, 读取一块加顺序读取后面3块

[参考](https://blog.csdn.net/LJFPHP/article/details/105318995)
### 二级索引(辅助索引)
==唯一索引, 普通索引, 前缀索引都是二级索引==
1. 唯一索引 (Unique key): 唯一索引是一种约束, 唯一索引的属性不能出现重复的值, 但可以为 null, 允许创建多个唯一索引. 目的在于数据的唯一性, ~~而非加快检索速度~~(会加快检索速度)
2. 普通索引 (index): 允许索引的key可以重复和为 null
3. 前缀索引 (prefix): 前缀索引只适用于字符串类型的数据, 是对==文本的前几个字符==建立索引, 因此数据量较小 (其实也是普通索引, 建立索引时 `alter table add index idx_email(email(6))` )
4. 全文索引 (full Text): 为了检索大文本数据中的关键词信息
#### 唯一索引和普通索引
[唯一索引和普通索引](https://segmentfault.com/a/1190000038321537)
### 覆盖索引
一个索引(对于二级索引而言)包含了所有需要查询的字段. 此时不需要回表(二次查询), 可以加快检索速度

### explain 语句
重要字段
1. type (排名分先后)
    - const(主键,最多仅匹配一条),
    - eq_ref(多表join, 对于前面的每一行, 在当前表中只能找到一行, 使用的是主键或唯一索引)
    - ref(多表join, 对于前面的每一行, 在当前能找到多行, 可用于 = 或 <=> (与null值比较, 相当于 is null) )
    - range(范围查找, 常见于 <=, between, like, in)
    - index(索引全部扫描, 如果使用了覆盖索引, 在extra中会显示 Using index)
    - all(全表扫描)
2. rows
**估算**需要扫描的条数, 越小越好
3. extra
    - using filesort, 表示不能通过索引达到排序, 需额外排序, 建议优化
    - using index, 表示覆盖索引
    - using temporary, 使用临时表, 一般出现于排序, 分组, 多表join的情况
### 索引创建的注意事项
1. 最左前缀
当联合索引为(colA, colB, colC)时, 只有按照索引创建的顺序作为查询条件, 才能使用索引. 换句话说, 如果查询条件仅包含 colB 或 colC时, 不能使用索引
2. 避免冗余索引
即命中 A索引, 必定能命中 B索引(一个(name)的索引, 一个(name, age)的索引), 此时应考虑删除其中一个
3. 对于字符串类型的字段, 考虑使用前缀索引, 能占用少一点的存储空间
4. 索引列不能表达式的一部分, 也不能是函数的参数, 否则无法使用索引
如:
    ```sql
    where id+1 = 2
    ```
5. 将选择性强的字段放在联合索引的前面
选择性: `count(distinct col)/count(*)` 选择性越高的索引价值越大

#### mysql 优化索引的情况
1. 索引下推
比如我们有一个联合索引 (name, age), 当我们查询`where name = "a%" and age = 20`
如果没有索引下推(mysql 5.6 之前), 则在查询索引时会直接忽略 age 这个字段, 找到所有的`name = a%` 的索引, 然后逐次回表查看 age 是否等于 20
![](https://pic3.zhimg.com/80/v2-04b4a496ab53eccc5feba150bf9fb7ea_1440w.jpg)
在有索引下推的情况下, 在索引查找到 `name="a%"` 的索引时, 会直接先查看 age 是否为 20, 如果否, 则直接忽略, 查找下一条索引
![](https://pic1.zhimg.com/80/v2-211aaba883221c81d5d7578783a80764_1440w.jpg)

## MySQL 执行一条 sql 语句的过程
![](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)
- 连接器:
    负责和客户端建立连接，获取用户权限以及维持和管理连接。
    通过 `show processlist`; 来查询连接的状态。在用户建立连接后，即使管理员改变连接用户的权限，也不会影响到已连接的用户。默认连接时长为 8 小时，超过时间后将会被断开。

    长连接：
    优势：在连接时间内，客户端一直使用同一连接，避免多次连接的资源消耗。
    劣势：在 MySQL 执行时，使用的内存被连接对象管理，由于长时间没有被释放，会导致系统内存溢出，被系统kill. 所以需要定期断开长连接，或执行大查询后，断开连接。MySQL 5.7 后，可以通过 `mysql_rest_connection` 初始化连接资源，不需要重连或者做权限验证


### binlog 与 redolog
#### binlog
binlog 用于记录数据库的写操作, 以==二进制的形式存放在硬盘中==, 属于 mysql 的==逻辑日志==, 由 server 层进行记录, 使用任何存储引擎的 mysql 数据库都会记录 binlog 日志
> 逻辑日志：可以简单理解为记录的就是sql语句

> 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更

##### 使用场景
1. 主从复制
2. 数据恢复

binlog用来做数据归档，但==不具备崩溃恢复==的能力，也就是说如果系统突然崩溃，重启后可能会有部分数据丢失
##### binlog 落盘时机
对于 InnoDB 存储引擎, 只有事务提交才会记录 binlog, 此时还在内存中, mysql 通过 sync_binlog 参数来控制 binlog 的落盘时机, 取值范围是 0~N
- 0: 不强制, 由系统决定
- 1: 每次 commit 都写入硬盘 (默认)
- N: 每 N 个事务, 落盘一次

##### binlog 的格式
- statement: 相当于保存 sql 语句, 需保留上下文
    优点: 不需要记录每一行的变化
    缺点: 需保留上下文, 且主从复制时, 可能由于版本不同导致某些函数执行结果不一致

- ==row: 基于行, 记录每一行的前后变化==
    优点: 强一致性
    缺点: 当出现更新多行时, 可能产生大量日志

> 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定

#### redo log
为了保证事务的==持久性==, innoDB 使用了 redo log,

==为什么不每次 commit 都落盘到数据表呢(为什么需要 redo log)(为什么不直接用 binlog)==
1. 因为 innoDB 是以页为单位与硬盘做交互, 如果因为一页的几个字节而进行一次 I/O, 将造成浪费, 而一条 redo log 日志的大小可能就只有几个字节，因此每次磁盘 IO 写入的数据量更小，那么耗时也会更短
2. 如果涉及多个页, 将造成随机I/O. 而 redo log 是顺序 IO, 不需要移动磁头


==InnoDB== 设计 redo log 这个==物理日志==, ==记录事务对数据页的修改==, (文件更小且是==顺序I/O==)
写日志虽然也是写磁盘，但是它是顺序写，相比随机写开销更小，能提升语句执行的性能

redo log 包括两部分: 
1. 内存中的缓存(redo log buffer) 
2. 磁盘上的日志文件 (redo log file)

==WAL(write-ahead logging) 日志先行:== 每个事务提交, 先将记录写入缓存, 后续某个节点再写到日志文件.

将 buffer 写到 redo log 的时机有以下选择
|参数值|含义|
|-|-|
|0（延迟写）==默认值==|事务提交时不会将redo log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到redo log file中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。|
|1（实时写，实时刷）==建议==|事务每次提交都会将redo log buffer中的日志写入os buffer并调用fsync()刷到redo log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能相对较差。==但也还好, 因为是顺序IO== |
|2（实时写，延迟刷）|每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到redo log file|

==建议: 双一, 即 redo log 和 binlog 的落盘时机都置为1==
##### redo log 记录形式
由于 redo log 记录的是数据页的变更, 因此不需要全部保留, 实际上采用的是==大小固定, 循环写入==的方式, 每个文件 1GB

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5bd580611e99442a8037c9b5f0b519bc~tplv-k3u1fbpfcp-zoom-1.image)

write pos表示redo log当前记录的LSN(逻辑序列号)位置，check point表示数据页更改记录刷盘后对应redo log所处的LSN(逻辑序列号)位置。write pos到check point之间的部分是redo log空着的部分，用于记录新的记录；check point到write pos之间是redo log待落盘的数据页更改记录。当write pos追上check point时，会先推动check point向前移动，空出位置再记录新的日志

启动innodb的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如binlog)要快很多。
重启innodb时，首先会检查磁盘中数据页的LSN，如果数据页的LSN小于日志中的LSN，则会从checkpoint开始恢复。

还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的LSN大于日志中的LSN，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做

#### binlog 和 redo log 区别
| | redo log | binlog |
|-|-|-|
|**文件大小**| 大小固定 | 可通过 max_binlog_size 设置每个 binlog 文件的大小|
|**实现方式**| innoDB 引擎层实现的 | server 层实现的, 所有引擎都能实现
|**记录方式**| 循环写 | 通过追加的方式, 当一个文件大于设定的大小, 后续日志会记录在新的文件上
|**使用场景**|崩溃恢复|主从复制和数据恢复

##### undo log
用于实现==原子性==, 其中记录每条写 sql 语句的反操作, 如 insert 语句, 在 undo 日志中是一条 delete 语句, 可以通过执行来达到回滚, 是 MVCC 的关键数据结构

### 查询语句
```sql
select * from student  A where A.age='18' and A.name='张三';
```
- 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在mysql8.0版本以前，会先查询缓存，以这条sql语句为key在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。
- 通过分析器进行词法分析，提取sql语句的关键元素，比如提取上面这个语句是查询select，提取需要查询的表名为tb_student,需要查询所有的列，查询条件是这个表的id='1'。然后判断这个sql语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
- 接下来就是优化器进行确定执行方案，上面的sql语句，可以有两种执行方案： a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是18。 b.先找出学生中年龄18岁的学生，然后再查询姓名为“张三”的学生。 那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。
- 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。
### 更新语句
```sql
update student A set A.age='19' where A.name='张三';
```
![](https://mmbiz.qpic.cn/mmbiz_jpg/4g5IMGibSxt5NE6forHc1x4yniarSIVe4MJ5iaYp2XqPic9ib7pC1PTFBzdoTKWhgkNkoIJ2dVYGpiaqLmfaJn49rATw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
- 先查询到张三这一条数据，如果有缓存，也是会用到缓存。
- 然后拿到查询的语句，把 age 改为19，然后调用引擎API接口，写入这一行数据，InnoDB引擎把数据保存在内存中，同时记录redo log，此时redo log进入prepare状态，然后告诉执行器，执行完成了，随时可以提交。
- 执行器收到通知后记录binlog，然后调用引擎接口，提交redo log 为提交状态。

#### 两阶段提交
![](https://cdn.nlark.com/yuque/0/2021/png/181910/1611294096654-a805a9de-3f14-44de-bb0c-cb344b40893c.png)
![](https://img2020.cnblogs.com/blog/1861307/202009/1861307-20200922152056410-1828606460.png)
浅色为 InnoDB 引擎执行, 深色为 server 执行

1. 如果在 redo log prepare 阶段崩溃(时刻 A), 重启后, redo log 没写入, 回滚
2. ~~在写 binlog 时崩溃, 重启后, binlog 未写入, 回滚~~
3. binlog 写完, 提交 redo log commit 状态时崩溃
    1. redo log 事务完整, 有 commit 标识, 直接提交
    2. redo log 只有 prepare 标识
        1. binlog 完整, 提交
        2. binlog 不完整, 回滚



如何判断 binlog 完整?
- statement 格式, 会有 commit 标识
- row 格式, 会有 XID event 标识
- 在 mysql 5.6 之后, 还有 binlog-checksum 参数, 来进行校验

为什么需要两阶段提交?
- 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致

# 三大范式
## 第一范式
属性不可再分
| Sno | Sname | Sdept | Mname | Cname | Grade |
| :---: | :---: | :---: | :---: | :---: |:---:|
| 1 | 学生-1 | 学院-1 | 院长-1 | 课程-1 | 90 |
| 2 | 学生-2 | 学院-2 | 院长-2 | 课程-2 | 80 |
| 2 | 学生-2 | 学院-2 | 院长-2 | 课程-1 | 100 |
| 3 | 学生-3 | 学院-2 | 院长-2 | 课程-2 | 95 |
## 第二范式
非主属性完全函数依赖于键码
如上表, 其中grade完全函数依赖于键码 (Sno, Cname), 因此可以拆分
| Sno | Sname | Sdept | Mname | Cname | Grade |
| :---: | :---: | :---: | :---: | :---: |:---:|
| 1 | 学生-1 | 学院-1 | 院长-1 | 课程-1 | 90 |
| 2 | 学生-2 | 学院-2 | 院长-2 | 课程-2 | 80 |
| 2 | 学生-2 | 学院-2 | 院长-2 | 课程-1 | 100 |
| 3 | 学生-3 | 学院-2 | 院长-2 | 课程-2 | 95 |

以上学生课程关系中，{Sno, Cname} 为键码，有如下函数依赖：
Sno -> Sname, Sdept
Sdept -> Mname
Sno, Cname-> Grade

Grade 完全函数依赖于键码，它没有任何冗余数据，每个学生的每门课都有特定的成绩。
Sname, Sdept 和 Mname 都部分依赖于键码，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。

分解后:
|Sno|Sname|Sdept|Mname|
|-|-|-|-|
|1 | 学生-1 | 学院-1 |院长-1|
|2 |学生-2 | 学院-2 | 院长-2 |
|3 | 学生-3	| 学院-2 | 院长-2 |
## 第三范式
非主属性不传递函数依赖于键码

如上表, 存在以下传递函数依赖 Sno -> Sdept -> Mname, 因此可以拆分



# Redis

## 为什么使用Redis
速度快，
1. 完全基于内存
2. 使用C语言实现
3. 单线程模型避免了不必要的上下文切换及竞争条件；

网络层使用epoll解决高并发问题，

​与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。

## redis与memcached
| redis | memcached |
| - | -|
|内存高速数据库|	高性能分布式内存缓存数据库，可缓存图片、视频|
支持hash、list、set、zset、string结构 |	只支持key-value结构
将大部分数据放到内存 |	全部数据放到内存中
支持持久化、主从复制备份 |不支持数据持久化及数据备份
数据丢失可通过AOF恢复|挂掉后，数据不可恢复

## redis 应用场景
1. 计数器
使用 incr, decr 指令(原子操作)
2. 会话缓存
​可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。
3. 分布式锁

## Redis 单线程模型详解
Redis 通过IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。

这样的好处非常明显： I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。

> Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。
当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

![](https://pic4.zhimg.com/80/v2-39a60b3ffc8f230595d286d51fe83e4f_1440w.jpg)

### 客户端与 redis 的一次通信
1. 在 Redis 启动初始化的时候，Redis 会将连接应答处理器跟 AE_READABLE 事件关联起来
2. 接着如果一个客户端跟Redis发起连接，此时会产生一个 AE_READABLE 事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的 Socket，同时将这个 Socket 的 AE_READABLE 事件跟命令请求处理器关联起来。
3. 当客户端向Redis发起请求的时候（不管是读请求还是写请求，都一样），首先就会在 Socket 产生一个 AE_READABLE 事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从Socket中读取请求相关数据，然后进行执行和处理。
4. 接着Redis这边准备好了给客户端的响应数据之后，就会将Socket的AE_WRITABLE事件跟命令回复处理器关联起来
5. 当客户端这边准备好读取响应数据时，就会在 Socket 上产生一个 AE_WRITABLE 事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入 Socket，供客户端来读取。
6. 命令回复处理器写完之后，就会删除这个 Socket 的 AE_WRITABLE 事件和命令回复处理器的关联关系

## redis 为什么单线程
1. 单线程编程容易并且更容易维护；
2. Redis 的性能瓶颈不再 CPU ，主要在内存和网络；
3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

## Redis6.0 之后为何引入了多线程？
Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

- 从socket中读取请求数据，会从内核态将数据拷贝到用户态 （read调用）
- 将数据回写到socket，会将数据从用户态拷贝到内核态 （write调用）

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。

1. 主线程负责==接收建立连接请求==，获取 socket 放入全局等待读处理队列
2. 主线程接收完所有读事件之后，通过 RR(Round Robin) 将这些连接分配给 IO 线程组 (一个命令可能得多次读 I/O)
3. 主线程阻塞等待 IO 线程组读取 socket 完毕
4. 主线程通过单线程的方式执行请求命令(指客户端发送的命令)，请求数据读取并解析完成
5. 主线程阻塞等待 IO 线程组将数据回写 socket 完毕
6. IO 线程组解除绑定，清空等待队列

![](https://pic4.zhimg.com/80/v2-7767cd6b08af6fc3fa404243959c219f_1440w.jpg)

## Redis 给缓存数据设置过期时间有啥用？
因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。
很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。

## Redis是如何判断数据是否过期的呢？
Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。
![](https://snailclimb.gitee.io/javaguide/docs/database/Redis/images/redis-all/redis%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4.png)

## 过期的数据的删除策略了解么？
1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

Redis 采用的是 定期删除+惰性/懒汉式删除
注意：并不是一次运行就检查所有的库，所有的键，而是随机检查一定数量的键。

定期删除函数的运行频率，在Redis2.6版本中，规定每秒运行10次，大概100ms运行一次。
在Redis2.8版本后，可以通过修改配置文件redis.conf 的 hz 选项来调整这个次数
## Redis 内存淘汰机制了解么？
Redis 提供 6 种数据淘汰策略：
1. volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
6. no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
7. volatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用(使用次数最少)的数据淘汰
8. allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用(使用次数最少)的 key



## redis 事务
redis 的事务不支持回滚, 因而不满足原子性. 因此Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且事务在执行的过程中，==不会被其他客户端发送来的命令请求所打断。==
redis 事务失败:
1. 语法错误(类似编译错误). 当事务队列中存在语法错误, 如`setqwe a a`时, 在输入 exec 后, redis 将丢弃整个队列
2. 类型错误(类似运行时错误). 当队列中有不符合键值的命令, 如对哈希键值使用`set hash a`, 在执行时, redis 将对该命令报错, 但事务队列的其他指令都能正常执行并返回

**watch关键词**(乐观锁实现)
当客户端 A 使用 watch 关键词监控键 `key`, 然后再开启事务(`multi`), 并对键 `key` 进行操作(增删改查). 此时如果客户端 B 修改了键 key, 则客户端 A 提交事务 exec 时, 将返回 nil(空), 即整个队列都丢弃,不执行
## 缓存穿透
缓存穿透说简单点就是==大量请求的 key 根本不存在(如 id < 0)==，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。
### 解决方法
0. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
1. 缓存无效key
2. 布隆过滤器

## 缓存雪崩
缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 
### 解决方法
1. 缓存不过期
2. 过期时间不相同
3. 加锁

## 缓存击穿
大量并发请求一个过期缓存, 导致此时缓存没有命中, 直接大量并发压垮数据库
### 解决方法
1. 热点缓存不过期, ==即把过期时间存在 value 中==
2. 在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降

## redis 底层数据结构
1. string
分为 3 种, int, 

### 跳表
==跳表增删查的平均时间复杂度为O(logn)==
#### 跳表的性质
- 由多层组成，最底层为第1层，次底层为第2层，以此类推。层数不会超过一个固定的最大值Lmax(32)。
- 每层都是一个有头节点的有序链表，第1层的链表包含跳表中的所有元素。
- 如果某个元素在第k层出现，那么在第1~k-1层也必定都会出现，但会按一定的概率p(0.25)在第k+1层出现。

第k层可以视为第k-1级索引，用来加速查找。为了避免占用空间过多，第1层之上都不存储实际数据，只有指针（包含指向同层下一个元素的指针与同一个元素下层的指针）。

![](https://upload-images.jianshu.io/upload_images/195230-c5c055a5ab1de6c5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### 插入元素
1. 按照前面讲过的查找流程，找到合适的插入位置。注意zset允许分数score相同，这时会根据节点数据obj的字典序来排序。
2. 调用zslRandomLevel()方法，随机出要插入的节点的层数。
3. 调用zslCreateNode()方法，根据层数level、分数score和数据obj创建出新节点。
4. 每层遍历，修改新节点以及其前后节点的前向指针forward和跳跃长度span，也要更新最底层的后向指针backward。

```c
int randomizeLevel(double p, int lmax) {
    int level = 1;
    Random random = new Random();
    while (random.nextDouble() < p && level < lmax) {
        level++;
    }
    return level;
}
```
#### zset (跳表+dict)
dict 的 key 是元素, value是分数

下图示出一个length=3，level=5的zskiplist。
![](https://upload-images.jianshu.io/upload_images/195230-8bb35614a101d7cf.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

可见，zskiplist的第1层是个双向链表，其他层仍然是单向链表，这样做是为了方便可能的逆向获取数据的需求。

另外，==节点中还会保存前向指针跳过的节点数span==，这是因为zset本身支持基于排名的操作，如zrevrank指令（由数据查询排名）、zrevrange指令（由排名范围查询数据）等。如果有span值的话，就可以方便地在查找过程中累积出排名了。

##### 为什么使用跳表
1. zset经常使用ZRANGE或ZREVRANGE操作，此时红黑树和平衡树并不能支持顺序遍历
2. 便于编写, 红黑树和平衡树需要旋转来保持平衡

### ziplist (压缩链表)
zset 在数据量比较小的情况，会使用 ziplist 来作为数据结构
ziplist 是一个连续的内存空间，设计上遵循着比较多的规矩，这种结构并不擅长更新操作。所以sortedset 、hash 都是在数据量小的情况使用这种结构。
#### 什么是ziplist
ziplist 是为了存储效率提供的一种经过特殊编码的双向链表。它用于存储字符串和整型，其中整型用二进制来进行编码，它能以O(1)的时间复杂度在表的两端提供push和pop操作。
格式可以表示为
```c
<zlbytes><zltail><zllen><entry>...<entry><zlend>
```

entry 的格式
```c
|<prelen><<encoding+lensize><len>><data>|
|---1----------------2--------------3---|
```

#### 内存结构
- zlbytes：32bit 表示ziplist占用的字节总数，其中包含自己本身占用的4个字节。
- zltail：32bit 表示ziplist 最后一个entry 距离列表起始地址有多少个字节。它的存在意味可以很方便地找到最后一项，而不需要遍历整个列表，并且可以快速的进行pop和push操作。
- zllen：16bit 表示entry的个数，zllen只有16bit 意味最大存储为216-1。如果entry的个数小于等于216-2，该值表示entry的个数。如果超过的话，zllen 所有的bit 都为1，那么如果需要求出entry的个数，就只能遍历整个列表了（我们可以从ziplistLen 这个API就可以看出来）。
- entry :表示真正存放数据的数据项。
    - prevlen :表示前一个数据项的字节总数，为了让ziplist能够从后向前遍历（从后一项的位置，只需向前偏移prevlen个字节，就找到了前一项。这里也就体现前面说的它像个单向链表的特性。prevlen这个字段采用的是变长编码。
    - encoding：表示当前数据项所保存数据的类型以及长度。也是采用变长编码。最前的2个字节决定存储是字符串类型还是整型，如果都为11的话表示为不同长度的整型，其他情况为字符串类型。

## redis 高可用
1. 持久化
2. 主从复制
3. 哨兵模式
4. 集群

### Redis 持久化机制
Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）
- RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。
- AOF持久化方式则会记录每一个服务器收到的==写操作==(读操作不记录)。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。
- Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。
- 两种方式的持久化是可以同时存在的，但是当Redis重启时，==AOF文件会被优先用于重建数据==

#### RDB
##### 工作原理
- Redis调用fork()，产生一个子进程。
- 子进程把数据写到一个临时的RDB文件。
- 当子进程写完新的RDB文件后，把旧的RDB文件替换掉。

> 关于fork. 
    1. 通过 fork 生成的父子进程会共享包括内存空间在内的资源；
    2. fork 函数并不会带来明显的性能开销，尤其是对内存进行大量的拷贝，它能通过写时拷贝将拷贝内存这一工作推迟到真正需要的时候；
    写时拷贝: 
    1. 在真正访问虚拟内存空间时，Kernel 会将虚拟内存映射到物理内存上，所以父子进程共享了物理上的内存空间；
    2. 当父进程或者子进程对共享的内存进行修改时，共享的内存才会以页为单位进行拷贝，父进程会**保留**原有的物理空间，而子进程会**使用拷贝后**的新物理空间；

**缺点:**
1. RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能正常工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。
2. RDB使用fork()产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成Redis停止服务几毫秒。如果数据量很大且**CPU性能不是很好**的时候，停止服务的时间甚至会到1秒。

##### 自动保存
修改配置文件redis.conf
```xml
# 格式为：save <seconds> <changes>
# 可以设置多个。
save 900 1 #900秒后至少1个key有变动
save 300 10 #300秒后至少10个key有变动
save 60 10000 #60秒后至少10000个key有变动
```

#### AOF
##### 工作原理
每当Redis接受到会**修改数据**集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。

**优点**:
1. 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。
2. AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用redis-check-aof这个工具很简单的进行修复。
3. 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。
4. AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用FLUSHALL命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。

**缺点:**
1. 在相同的数据集下，AOF文件的大小一般会比RDB文件大。
2. 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。

##### 自动保存
配置Redis调用fsync的频率，有三个选项：
```xml
appendfsync always #每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。
appendfsync everysec #每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。
appendfsync no #从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。
```

##### 重写
某些命令可以精简, 比如递增, 我们只需要记住当前值即可
**原理:**
1. Redis调用fork()，产生一个子进程。
2. 子进程把新的AOF写到一个临时文件里。
3. 主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。
4. 当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。


### 主从复制
为了避免服务的单点故障，会把数据复制到多个副本放在不同的服务器上，且这些拥有数据副本的服务器可以用于处理客户端的读请求，扩展整体的性能
**好处:**
1. 数据冗余，实现数据的热备份
2. 故障恢复，避免单点故障带来的服务不可用
3. 读写分离，负载均衡。主节点负载读写，从节点负责读，提高服务器并发量
4. 高可用基础，是哨兵机制和集群实现的基础
#### 过程
1. 建立连接
    1. 从服务器执行 slaveOf 命令, 创建连向主服务器的套接字
    2. 从服务器发送 ping 命令, 主服务器返回 pong, 否则从服务器将重连
    3. 身份验证
    4. 从服务器发送自己的监听窗口
2. 数据同步 (PSYNC指令)
分为**完整重同步(full resynchronization)** 和 **部分重同步(partial resynchronization)**
**完整重同步**
    1. 从服务器发送 psync 指令
    2. 主服务器收到后, 执行 bgsave 指令, 并使用缓冲区记录这期间的写操作
    3. 主服务器发送快照文件
    4. 主服务器发送缓冲区里的写指令

    ![](https://user-gold-cdn.xitu.io/2019/9/17/16d3ea1dbeb04fc9?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
**部分重同步**   
用于处理从服务器断线后重连
    - runid (replication id): 主服务器的 id
    - offset: 复制偏移量, 主从都有, 表示发送(接收)的字节偏移
    - replication backlog buffer: 复制积压缓冲区. 由 master 节点维护, 作用在于备份最近主服务器发送给从服务器的数据

    当 slave 重新连接到 master, 会执行 `PSYNC <runid> <offset>` 发送旧的 master 的 id, 和已接收的 offset. ==但如果 master 缓冲区积压的数据不够, 或 runid 不一致, 将会进行完整重同步==
    ![](https://user-gold-cdn.xitu.io/2019/9/17/16d3ea1dbf509bd1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### 哨兵模式
Redis 的 Sentinel 系统可以用来管理多个 Redis 服务器, 哨兵系统主要有以下几项任务
- 监控: 不断检查主, 从服务器是否正常运行
- 通知: 当某个节点出现问题, 可以通过 api 向管理员发送通知
- 故障转移: 当主服务器出现故障, 哨兵系统会自动选举出某个从节点作为新的主节点
- 提供配置: 客户端连接的是哨兵系统以获得主节点的信息

![](https://user-gold-cdn.xitu.io/2018/8/22/16560ce61dbc4eeb)

**工作原理:**
每个哨兵节点都需要执行定期任务
1. 每秒一次向所有主/从服务器及其他哨兵发送 ping 命令
![](https://user-gold-cdn.xitu.io/2018/8/22/16560ce61df44c4d)
2. 如果一个节点超过 down-after-milliseconds 还没有回复 ping 命令, 则会被该哨兵标记为主观下线
![](https://user-gold-cdn.xitu.io/2018/8/22/16560ce61dc739de)
3. 如果一个主服务器被标记为主观下线, 那么所有监控主服务器的哨兵, 要每秒一次确认主服务器进入主观下线
![](https://user-gold-cdn.xitu.io/2018/8/22/16560ce647a39535)
4. 如果一个主服务器被标记主观下线, 且有足够的哨兵(可以配置) 同意, 那么这个主服务器被标记为客观下线
![](https://user-gold-cdn.xitu.io/2018/8/22/16560ce647c2583e)
5. 需要选出哨兵的 leader 
#### 故障转移(选举制度)
选出大佬哨兵后，大佬哨兵就会对故障进行自动回复，从slave中选出一名slave作为主数据库，选举的规则如下所示：

1. 所有的slave中slave-priority优先级最高的会被选中。
2. 若是优先级相同，会选择偏移量最大的，因为偏移量记录着数据的复制的增量，越大表示数据越完整。
3. 若是以上两者都相同，选择ID最小的

### redis 集群
![](https://static001.infoq.cn/resource/image/f7/7c/f70609a78f2429832cec2ecf54707d7c.png)

以上图片，蓝色的为 redis 节点，这里是指 master 节点，一个 master 节点可以配置多个 slave。绿色为客户端，可以理解为我们的应用。

#### 数据分片
##### 数据分片算法
###### 顺序分布
顺序分布假设每个节点最多存33个数字，那么此时需要4个节点，节点1存数字1 ~ 33，节点2存数字34 ~ 66，节点3存数字67 ~ 99，节点4存数字100.
**优点**:可支持顺序访问,所有的Hash分布算法都不支持顺序访问。
**缺点**：均匀性不够，数据分散度不够。
###### 哈希分布
1. **普通哈希**
将 key 做哈希后取余
**缺点**: 稳定性太差, 新增节点数据做很多偏移
2. **一致性哈希**
**原理:**
> 1.将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环就是下图中的黑色圆环
2.对每个服务器的唯一识别标志（IP或者主机名）求hash值，将得到的值放入第一步的圆环中对应的位置。如下图的node1 node2 node3 node4
3.对要保存的数据的key求hash值，将得到的值落入圆环中，就是下图的黄色圆圈，然后在圆环中顺时针找到最近的node（服务器的唯一识别标志（IP或者主机名）求hash值落在圆环中所在的点），该数据就存储在该node中

![](https://img-blog.csdn.net/2018080720553729?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5MDIyNjg4Nzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**伸缩影响**:
> 1.挂了一台服务器：比如上图中，node2挂了，只会影响node4节点（Node2顺时针往下走第一个节点），node2的数据会全部迁移到node4节点上。其余节点上的数据不用迁移。
2.如果多加一台服务器： 比如上图中，在node4和node3之间加入node5，node3（node5顺时针往下走第一个节点）中的数据会有一部分符合要求的被迁移到Node5上。

**缺点**: 稳定性不足, 当节点较小的时候, 可能数据倾斜严重

3. **虚拟槽分区 hash slot (redis集群采用)**
![](https://img-blog.csdn.net/20180807210508967?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5MDIyNjg4Nzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**原理**:
> 1.redis cluster共有16384（0 ~ 16383）个hash槽，分在集群不同的节点上。比如下图中，0 ~ 3276范围的槽在node1上，3277 ~ 6553范围的槽在node2上，以此类推。
2.对key做crc16(key)算出的值再对16383取余，最终得到的结果就是该key在哪个槽(==一个槽有多个 key==)上。
3.集群维护了槽和节点的对应关系，通过第二步得到Key在哪个槽上就能知道key在哪个集器上


#### 扩容集群
![](https://user-gold-cdn.xitu.io/2019/5/24/16aea012c36d5555?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
1. 首先启动一个新节点 M4
2. 执行 cluster meet 命令, 将 M4 加入集群
3. 发送 cluster setslot {slot} importing {M4} 操作
4. 其他节点 cluster setslot {slot} migrating {M} 操作
5. 其他节点统计属于要迁移的 slot 的键值, 然后把键值通过 pipeline 迁移到目标节点
6. 通知其他节点更新 slot 映射, slot 已发生迁移

#### 收缩集群
![](https://user-gold-cdn.xitu.io/2019/5/24/16aea012c352cecc?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
1. 首先需要确认下线节点是否有负责的槽，如果是，需要把槽迁移到其他节点，保证节点下线后整个集群槽节点映射的完整性。
2. 当下线节点不再负责槽或者本身是从节点时，就可以通知集群内其他节点忘记下线节点，当所有的节点忘记改节点后可以正常关闭。

#### 客户端
![](https://user-gold-cdn.xitu.io/2019/5/24/16aea013652e421b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

1. 客户端根据本地 slot 缓存发送命令到源节点，如果存在键对应则直接执行并返回结果给客户端。
2. 如果节点返回 MOVED 错误(slot 已迁移完毕)，==更新本地(客户端)的 slot 到 Redis 节点的映射关系==，然后重新发起请求。
3. 如果数据正在迁移中，节点会回复 ASK 重定向异常。格式如下: ( error ) ASK { slot } { targetIP } : {targetPort}
客户端从 ASK 重定向异常提取出目标节点信息，发送 asking 命令到目标节点打开客户端连接标识，再执行键命令。

#### 非阻塞迁移
![](https://static001.infoq.cn/resource/image/99/7c/991fb59e0d86c5ba89f9e339fc2cd77c.png)
![](https://static001.infoq.cn/resource/image/da/b5/da87c0434eac7fe9c1000010405373b5.png)
1. 如果一个槽被设置为 MIGRATING 状态时，原本持有该槽的节点会继续接受关于这个槽的命令请求，但==只有当键存在于该节点时，节点才会处理这个请求==。如果命令所使用的键不存在于该节点，那么节点将向客户端返回一个 ASK 转向（redirection）错误，告知客户端，要将命令请求发送到槽的迁移目标节点。
2. 如果一个槽被设置为 IMPORTING 状态时，节点仅在接收到 ASKING 命令之后，才会接受关于这个槽的命令请求。如果客户端向节点发送该槽的数据请求，命令为非 ASKING 时，那么节点会使用 MOVED 转向错误将命令请求转向至真正负责处理这个槽的节点。

#### 节点内部结构
![](https://static001.infoq.cn/resource/image/85/f8/85e4980fcd0bc748b3514f0afb8bf7f8.png)
![](https://static001.infoq.cn/resource/image/b9/c8/b9a5179a680328b8198cfa0dfbc80fc8.png)
![](https://static001.infoq.cn/resource/image/87/c0/874f4453b4ef3522683633e1eb06a3c0.png)
![](https://static001.infoq.cn/resource/image/4c/88/4cad01e201938072524dfe7927da5888.png)

#### 集群响应客户端操作流程
1. 检查 key 所在的 slot 是否属于当前节点
    1. 计算 crc16(key) % 16384 得到 slot
    2. 查询 clusterState.slots 负责的节点并与 myself 指针比较
2. 若不属于, 返回 MOVED 重定向
3. 若属于
    1. key 存在, 响应请求 (不管是否在迁移)
    2. key 不存在
        1. slot 处于 migrating(迁出) 状态, 返回 ASK 
        2. slot 处于 importing(迁入) 状态
            1. 请求带有 ASKING 标志, 响应请求
            2. 不带有 ASKING 标志, 返回 MOVED




